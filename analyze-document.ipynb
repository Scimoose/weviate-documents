{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = UnstructuredPDFLoader(\"attention.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 documents in your data.\n",
      "There are 39933 characters in the first document.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()\n",
    "\n",
    "print (f'You have {len(data)} documents in your data.')\n",
    "print(f'There are {len(data[0].page_content)} characters in the first document.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk data into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43 chunked documents now.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print(f'There are {len(texts)} chunked documents now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='7\\n\\n1\\n\\n0\\n\\n2\\n\\nc\\n\\ne\\n\\nD\\n\\n6\\n\\n]\\n\\nL\\n\\nC\\n\\n.\\n\\ns\\n\\nc\\n\\n[\\n\\n5\\n\\nv\\n\\n2\\n\\n6\\n\\n7\\n\\n3\\n\\n0\\n\\n.\\n\\n6\\n\\n0\\n\\n7\\n\\n1\\n\\n:\\n\\nv\\n\\ni\\n\\nX\\n\\nr\\n\\na\\n\\nAttention Is All You Need\\n\\nAshish Vaswani∗\\n\\nGoogle Brain\\n\\navaswani@google.com\\n\\nNoam Shazeer∗\\n\\nGoogle Brain\\n\\nnoam@google.com\\n\\nNiki Parmar∗\\n\\nGoogle Research\\n\\nnikip@google.com\\n\\nJakob Uszkoreit∗\\n\\nGoogle Research\\n\\nusz@google.com\\n\\nLlion Jones∗\\n\\nGoogle Research\\n\\nllion@google.com\\n\\nAidan N. Gomez∗ †\\n\\nUniversity of Toronto\\n\\naidan@cs.toronto.edu\\n\\nŁukasz Kaiser∗\\n\\nGoogle Brain\\n\\nlukaszkaiser@google.com\\n\\nIllia Polosukhin∗ ‡\\n\\nillia.polosukhin@gmail.com\\n\\nAbstract\\n\\nThe dominant sequence transduction models are based on complex recurrent or\\n\\nconvolutional neural networks that include an encoder and a decoder. The best\\n\\nperforming models also connect the encoder and decoder through an attention\\n\\nmechanism. We propose a new simple network architecture, the Transformer,\\n\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions', lookup_str='', metadata={'source': 'attention.pdf'}, lookup_index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings creation for the documents to get them ready for semantic search\n",
    "\n",
    "For more information on how to use Weaviate https://weaviate.io/developers/weaviate/quickstart/end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'Document',\n",
       "   'description': \"This property was generated by Weaviate's auto-schema feature on Mon Apr 24 19:59:29 2023\",\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': \"This property was generated by Weaviate's auto-schema feature on Mon Apr 24 19:59:29 2023\",\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'text',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': \"This property was generated by Weaviate's auto-schema feature on Mon Apr 24 19:59:29 2023\",\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'source',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores.weaviate import Weaviate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import weaviate\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# docker-compose up -d to run, docker-compose down to stop\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "weaviate = Weaviate(client, \"Document\", \"text\")\n",
    "# weaviate.add_documents(texts) # run once to add documents to weaviate\n",
    "\n",
    "# you can also go to http://localhost:8080/v1/objects to see the documents\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Created once at the very beginning, no need to recreate\n",
    "\n",
    "schema = {\n",
    "    \"classes\": [\n",
    "    {\n",
    "      \"class\": \"Document\",\n",
    "      \"description\": \"A document\",\n",
    "      \"vectorizer\": \"text2vec-openai\",\n",
    "      \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "          \"model\": \"ada\",\n",
    "          \"modelVersion\": \"002\",\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "      },\n",
    "      \"properties\": [{\n",
    "                \"name\": \"content\",\n",
    "                \"dataType\": [\"text\"],\n",
    "                }]\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(schema)\n",
    "client.schema.get()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a question or dialogue to get started!\n",
      " Transformers are trained faster than architectures based on recurrent or convolutional layers and they allow for significantly more parallelization. They also require significantly less time to train than convolutional neural networks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "\n",
    "MyOpenAI = OpenAI()\n",
    "qa = ChatVectorDBChain.from_llm(MyOpenAI, weaviate)\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "print(\"Please enter a question or dialogue to get started!\")\n",
    "\n",
    "query = input(\"\")\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])\n",
    "chat_history = [(query, result[\"answer\"])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
